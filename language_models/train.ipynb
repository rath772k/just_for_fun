{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/paul_graham_essay.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75012"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YWgs4e.tILj;cy3K+\\'ia,v zN7[0E!DuHMC6p1T\\nArqR8\"Vlx]$XB%Umnkâ€”-29&So/O:(f5hJwGbFPd)?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some random string\n"
     ]
    }
   ],
   "source": [
    "stoi = {char: idx for idx, char in enumerate(vocab)}\n",
    "itos = {idx: char for char, idx in stoi.items()}\n",
    "\n",
    "def encode(text):\n",
    "    return [stoi[char] for char in text]\n",
    "\n",
    "def decode(tokens):\n",
    "    return \"\".join(itos[token] for token in tokens)\n",
    "\n",
    "test_text = \"some random string\"\n",
    "\n",
    "print(decode(encode(test_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenized_data = torch.tensor(encode(data), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(tokenized_data))\n",
    "train_data = tokenized_data[:n]\n",
    "test_data = tokenized_data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer\n",
    "import importlib\n",
    "importlib.reload(transformer)\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBED_SIZE = 384\n",
    "NUM_HEADS = 8\n",
    "CONTEXT_LENGTH = 16\n",
    "NUM_LAYERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (token_embedding): Embedding(81, 384)\n",
       "  (pos_embedding): Embedding(16, 384)\n",
       "  (attn_blocks): ModuleList(\n",
       "    (0-5): 6 x AttentionBlock(\n",
       "      (attn_heads): ModuleList(\n",
       "        (0-7): 8 x CausalSelfAttention(\n",
       "          (Q): Linear(in_features=384, out_features=48, bias=False)\n",
       "          (K): Linear(in_features=384, out_features=48, bias=False)\n",
       "          (V): Linear(in_features=384, out_features=48, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (fcn): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (activation): ReLU()\n",
       "        (proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=81, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Transformer(vocab_size=VOCAB_SIZE, embed_size=EMBED_SIZE, num_heads=NUM_HEADS, context_length=CONTEXT_LENGTH, num_layers=NUM_LAYERS)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = CONTEXT_LENGTH\n",
    "batch_size = 32\n",
    "unif = torch.ones(train_data.shape[0] - context_length)\n",
    "unif.to(device)\n",
    "def get_batch():\n",
    "    batch_indices = unif.multinomial(batch_size, replacement=False)\n",
    "    inputs = torch.stack([train_data[i:i+context_length] for i in batch_indices])\n",
    "    targets = torch.stack([train_data[i+1:i+1+context_length] for i in batch_indices])\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    return inputs, targets\n",
    "\n",
    "logits, loss = m(*get_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 81])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6083, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[78, 22, 75, 13, 22, 71,  5, 41, 22,  3,  7, 31, 78,  5, 56,  7],\n",
      "        [ 7, 71,  5, 22, 12,  5, 18, 47, 18, 56,  2,  6, 22,  1, 71, 18],\n",
      "        [ 5,  5, 56, 22, 69,  5, 19,  3, 18, 75, 47,  5, 22, 19,  7, 22],\n",
      "        [56,  7, 47, 13, 22,  3, 18, 56, 12,  5, 22, 73,  5, 22,  3,  7],\n",
      "        [19, 12, 57, 22, 18, 56,  7, 64, 22,  3, 71, 19, 36,  5, 20, 22],\n",
      "        [78, 22,  3,  7, 41, 19, 56,  2,  5, 22, 19, 78, 21, 18, 12,  5],\n",
      "        [ 7, 71, 18,  3, 22, 56,  5, 73, 22, 12, 64, 55, 36, 19, 56, 13],\n",
      "        [56, 18, 23,  5, 78, 20, 22, 12,  5, 41,  7, 19, 18, 56, 47, 13],\n",
      "        [18, 56,  2, 22, 47, 18, 69,  5, 22, 41, 18,  2, 71,  7,  6, 22],\n",
      "        [64, 31, 47, 78, 22,  5, 21,  5, 56, 22, 41,  5, 19, 47, 18, 23],\n",
      "        [22, 69,  5, 73, 22, 55, 64, 56,  7, 71,  3,  6, 22, 24, 64, 41],\n",
      "        [75, 31,  7, 22,  5, 48, 36, 47, 18, 12, 18,  7, 47, 13, 22, 78],\n",
      "        [56, 22,  5,  3,  3, 19, 13, 22,  8, 17, 55, 22,  2, 64, 18, 56],\n",
      "        [22,  5, 56, 78, 22, 64, 69, 22,  7, 71,  5, 22,  3, 31, 55, 55],\n",
      "        [64, 22, 78, 18, 78, 22,  3, 55, 19, 47, 47,  5, 41, 22, 18, 56],\n",
      "        [ 5, 56,  7, 22, 64, 56, 22,  7, 64, 22, 69, 64, 31, 56, 78, 22],\n",
      "        [22, 19, 22, 47, 19, 56,  2, 31, 19,  2,  5, 22, 78,  5, 69, 18],\n",
      "        [22, 71, 19, 41, 78, 22, 73, 71,  5, 56, 22, 18,  7, 22, 78, 18],\n",
      "        [22,  7, 71,  5, 22, 56,  5, 48,  7, 22, 69,  5, 73, 22, 13,  5],\n",
      "        [41,  7, 31, 36,  6, 22, 33, 19, 13, 75,  5, 22,  7, 71,  5, 13],\n",
      "        [22, 19,  7, 22,  7, 71,  5, 22, 36, 41, 64,  3, 36,  5, 12,  7],\n",
      "        [ 3, 22,  3, 47, 18,  2, 71,  7, 47, 13, 22, 78, 18,  3, 55, 19],\n",
      "        [19, 56, 78, 22, 21, 19, 41, 18, 64, 31,  3, 22, 41,  5, 19, 47],\n",
      "        [56, 17,  7, 22, 73, 19, 56,  7, 22,  7, 64, 22, 71, 19, 21,  5],\n",
      "        [13, 22, 32,  5, 18, 56, 47,  5, 18, 56, 22, 12, 19, 47, 47,  5],\n",
      "        [ 5, 22,  7, 71, 19,  7, 22,  9, 18,  3, 36, 22, 73, 19,  3, 22],\n",
      "        [38, 71,  5, 41,  5, 22, 73,  5, 41,  5, 22,  3, 64, 55,  5, 22],\n",
      "        [64, 41, 57, 18, 56,  2, 22, 64, 56, 22, 19, 56, 22, 18, 56,  7],\n",
      "        [22,  7, 71,  5, 22, 41,  5, 56,  7, 20, 22, 55, 13, 22, 75, 31],\n",
      "        [55, 36, 41,  5,  3,  3,  5, 78, 22, 19, 56, 78, 22,  5, 56, 21],\n",
      "        [13, 64, 31, 22, 55, 18,  2, 71,  7, 22,  2, 64, 22, 64, 31,  7],\n",
      "        [22,  9, 18,  3, 36, 22, 71, 19, 12, 57,  5, 41, 22,  7, 64, 22]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[78, 22, 75, 13, 22, 71,  5, 41, 22,  3,  7, 31, 78,  5, 56,  7, 65],\n",
       "        [ 7, 71,  5, 22, 12,  5, 18, 47, 18, 56,  2,  6, 22,  1, 71, 18, 76],\n",
       "        [ 5,  5, 56, 22, 69,  5, 19,  3, 18, 75, 47,  5, 22, 19,  7, 22, 34],\n",
       "        [56,  7, 47, 13, 22,  3, 18, 56, 12,  5, 22, 73,  5, 22,  3,  7, 52],\n",
       "        [19, 12, 57, 22, 18, 56,  7, 64, 22,  3, 71, 19, 36,  5, 20, 22, 34],\n",
       "        [78, 22,  3,  7, 41, 19, 56,  2,  5, 22, 19, 78, 21, 18, 12,  5, 11],\n",
       "        [ 7, 71, 18,  3, 22, 56,  5, 73, 22, 12, 64, 55, 36, 19, 56, 13, 55],\n",
       "        [56, 18, 23,  5, 78, 20, 22, 12,  5, 41,  7, 19, 18, 56, 47, 13, 63],\n",
       "        [18, 56,  2, 22, 47, 18, 69,  5, 22, 41, 18,  2, 71,  7,  6, 22, 13],\n",
       "        [64, 31, 47, 78, 22,  5, 21,  5, 56, 22, 41,  5, 19, 47, 18, 23, 59],\n",
       "        [22, 69,  5, 73, 22, 55, 64, 56,  7, 71,  3,  6, 22, 24, 64, 41, 16],\n",
       "        [75, 31,  7, 22,  5, 48, 36, 47, 18, 12, 18,  7, 47, 13, 22, 78, 60],\n",
       "        [56, 22,  5,  3,  3, 19, 13, 22,  8, 17, 55, 22,  2, 64, 18, 56, 62],\n",
       "        [22,  5, 56, 78, 22, 64, 69, 22,  7, 71,  5, 22,  3, 31, 55, 55, 67],\n",
       "        [64, 22, 78, 18, 78, 22,  3, 55, 19, 47, 47,  5, 41, 22, 18, 56,  7],\n",
       "        [ 5, 56,  7, 22, 64, 56, 22,  7, 64, 22, 69, 64, 31, 56, 78, 22,  2],\n",
       "        [22, 19, 22, 47, 19, 56,  2, 31, 19,  2,  5, 22, 78,  5, 69, 18, 50],\n",
       "        [22, 71, 19, 41, 78, 22, 73, 71,  5, 56, 22, 18,  7, 22, 78, 18, 57],\n",
       "        [22,  7, 71,  5, 22, 56,  5, 48,  7, 22, 69,  5, 73, 22, 13,  5, 61],\n",
       "        [41,  7, 31, 36,  6, 22, 33, 19, 13, 75,  5, 22,  7, 71,  5, 13, 37],\n",
       "        [22, 19,  7, 22,  7, 71,  5, 22, 36, 41, 64,  3, 36,  5, 12,  7, 28],\n",
       "        [ 3, 22,  3, 47, 18,  2, 71,  7, 47, 13, 22, 78, 18,  3, 55, 19, 51],\n",
       "        [19, 56, 78, 22, 21, 19, 41, 18, 64, 31,  3, 22, 41,  5, 19, 47, 41],\n",
       "        [56, 17,  7, 22, 73, 19, 56,  7, 22,  7, 64, 22, 71, 19, 21,  5, 60],\n",
       "        [13, 22, 32,  5, 18, 56, 47,  5, 18, 56, 22, 12, 19, 47, 47,  5, 32],\n",
       "        [ 5, 22,  7, 71, 19,  7, 22,  9, 18,  3, 36, 22, 73, 19,  3, 22,  1],\n",
       "        [38, 71,  5, 41,  5, 22, 73,  5, 41,  5, 22,  3, 64, 55,  5, 22, 26],\n",
       "        [64, 41, 57, 18, 56,  2, 22, 64, 56, 22, 19, 56, 22, 18, 56,  7, 64],\n",
       "        [22,  7, 71,  5, 22, 41,  5, 56,  7, 20, 22, 55, 13, 22, 75, 31, 56],\n",
       "        [55, 36, 41,  5,  3,  3,  5, 78, 22, 19, 56, 78, 22,  5, 56, 21, 38],\n",
       "        [13, 64, 31, 22, 55, 18,  2, 71,  7, 22,  2, 64, 22, 64, 31,  7, 26],\n",
       "        [22,  9, 18,  3, 36, 22, 71, 19, 12, 57,  5, 41, 22,  7, 64, 22, 18]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = get_batch()[0]\n",
    "print(start_idx)\n",
    "m.generate(start_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"d by her studentVe$%7I8Tz$UwOf$3v$CTkCnEOH+(fUA]-UY,poaUz8/DW[CCP]4,XtC37OwyD6k9vCCIC\\nmyYiCG3TK!V9OTDD[WE3Iw]jGPT'C&\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(start_idx, 100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(params=m.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.044907569885254\n",
      "1.1167418956756592\n",
      "1.0756452083587646\n",
      "1.0323002338409424\n",
      "1.014737606048584\n",
      "0.9621953964233398\n",
      "1.0066713094711304\n",
      "0.8820263147354126\n",
      "0.9256763458251953\n",
      "0.9642428159713745\n"
     ]
    }
   ],
   "source": [
    "# this is not the first run\n",
    "for step in range(1000):\n",
    "    _, loss = m(*get_batch())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was an early ram, so off maine days, to but to do) I was in retain me, but painting the that Interleaf in I was onaY was a penter of the store that sourgent now that we had to beauild about retail, so it as puccally later anything to write the student prestigious on this poitten by Bento Word: witch. At the time thinking. Witor kind of work on it on my writing Rtm to offer raisons vesters that art nurned ough something last compositions of with AI, as we should I ran ealient proximation of the right to be one dayer in New York.\n",
      "\n",
      "Computs of new kind of some sort of be than about Lisp was hacking when I husked for the language is a book. [2]\n",
      "\n",
      "I wanted not me to RISD, but it was not documentary to layous, so off the visual cues begied. In because that it on my model to get a mother of days of Harvalual stocks wouldn't need very engaging. So main more than intestood is a book, now I was a difficult surprise,  the started to sign but to du0. I kept that instead the channel language. We knew unde\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(decode(m.generate(torch.tensor([encode(\"I was a\")], device=device), 1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
