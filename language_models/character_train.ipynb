{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tokenizers import CharacterTokenizer\n",
    "import torch\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_PATH = \"tokenizers/character_tokenizer.pkl\"\n",
    "DATA_PATH = \"../data/paul_graham_essay.txt\"\n",
    "TRAIN_DATA_PATH = \"train.pt\"\n",
    "TEST_DATA_PATH = \"test.pt\"\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "EMBED_SIZE = 384\n",
    "NUM_HEADS = 8\n",
    "CONTEXT_LENGTH = 16\n",
    "NUM_LAYERS = 6\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(TOKENIZER_PATH, \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "except:\n",
    "    tokenizer = CharacterTokenizer.build_tokenizer(DATA_PATH)\n",
    "    with open(TOKENIZER_PATH, \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_data = torch.load(TRAIN_DATA_PATH)\n",
    "    test_data = torch.load(TEST_DATA_PATH)\n",
    "except:\n",
    "    with open(DATA_PATH, \"r\") as f:\n",
    "        data = f.read()\n",
    "    tokenized_data = torch.tensor(tokenizer.encode(data), dtype=torch.long)\n",
    "    n = int(0.9 * len(tokenized_data))\n",
    "    train_data = tokenized_data[:n]\n",
    "    test_data = tokenized_data[n:]\n",
    "    torch.save(train_data, TRAIN_DATA_PATH)\n",
    "    torch.save(test_data, TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (token_embedding): Embedding(81, 384)\n",
       "  (pos_embedding): Embedding(16, 384)\n",
       "  (attn_blocks): ModuleList(\n",
       "    (0-5): 6 x AttentionBlock(\n",
       "      (attn_heads): ModuleList(\n",
       "        (0-7): 8 x CausalSelfAttention(\n",
       "          (Q): Linear(in_features=384, out_features=48, bias=False)\n",
       "          (K): Linear(in_features=384, out_features=48, bias=False)\n",
       "          (V): Linear(in_features=384, out_features=48, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (fcn): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (activation): ReLU()\n",
       "        (proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=81, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_size=EMBED_SIZE,\n",
    "    num_heads=NUM_HEADS,\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    num_layers=NUM_LAYERS,\n",
    ")\n",
    "m.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif = torch.ones(train_data.shape[0] - CONTEXT_LENGTH, device=DEVICE)\n",
    "\n",
    "\n",
    "def get_batch():\n",
    "    batch_indices = unif.multinomial(BATCH_SIZE, replacement=False)\n",
    "    inputs = torch.stack([train_data[i : i + CONTEXT_LENGTH] for i in batch_indices])\n",
    "    targets = torch.stack(\n",
    "        [train_data[i + 1 : i + 1 + CONTEXT_LENGTH] for i in batch_indices]\n",
    "    )\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "logits, loss = m(*get_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 81])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.586947917938232"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[31, 43, 12,  5, 25,  6, 74, 20, 67, 43,  5, 20, 43, 28, 25, 62],\n",
      "        [ 5, 17, 64, 31, 43, 31,  5, 43, 44, 20, 31, 43, 44, 62, 73, 17],\n",
      "        [64, 74, 52, 72, 78, 31, 43, 44, 52, 43, 44, 43, 57,  5,  5,  6],\n",
      "        [64, 78, 43, 37, 43, 12, 44, 73, 62, 72, 78, 31, 43, 73, 72, 78],\n",
      "        [44, 25, 44, 20, 73, 78, 78, 43,  0,  5, 17, 27, 25, 78, 43,  5],\n",
      "        [44, 64, 43, 37, 20, 73, 78, 64, 64, 74, 67, 78, 20, 62, 78, 76],\n",
      "        [ 5, 17, 64, 31, 43, 57, 44, 25, 78, 64,  0, 43, 17, 20, 31, 78],\n",
      "        [43, 44, 43, 53, 52, 62, 72, 73, 74, 62,  6, 53, 29, 43, 52,  5],\n",
      "        [43, 51, 17, 52, 73, 43, 52, 74, 73, 73, 74, 20, 67, 43, 74, 20],\n",
      "        [78, 43, 78, 20, 31, 43,  5, 63, 43, 73, 72, 78, 43,  0, 78, 44],\n",
      "        [72,  5, 12, 43, 73, 72, 78, 43,  4, 44, 74, 20, 73, 74, 20, 67],\n",
      "        [72, 44, 73, 43, 74, 73, 43, 64, 78, 44, 31, 52, 43, 73,  5, 43],\n",
      "        [74, 78, 31, 43, 12, 78, 43, 12, 78, 25, 78, 43, 64, 44, 73, 78],\n",
      "        [43, 67, 44, 46, 78, 43, 73, 72, 74, 52, 43, 73, 44, 64,  6, 55],\n",
      "        [76, 43, 37, 43, 12, 44, 20, 73, 78, 31, 43, 65, 75, 43, 73,  5],\n",
      "        [20, 43, 60, 17, 62, 72, 43, 73, 72, 78, 43, 52, 44, 60, 78, 43],\n",
      "        [17, 44, 64, 64,  0, 43, 62, 72,  5,  5, 52, 78, 43, 12, 72, 44],\n",
      "        [ 5, 17, 64, 31, 43, 60, 44,  6, 78, 43, 44, 43, 64, 44, 25, 67],\n",
      "        [76, 43, 34, 78, 43,  5, 20, 64,  0, 43, 60, 78, 44, 20, 73, 43],\n",
      "        [44, 25, 73, 60, 78, 20, 73, 55, 43, 52, 78, 44, 64, 78, 31, 43],\n",
      "        [78, 62, 44, 17, 52, 78, 43, 72, 78, 43, 12,  5, 17, 64, 31, 43],\n",
      "        [46, 78, 43, 73,  5, 43,  4, 44, 74, 20, 73, 43, 52,  5, 60, 78],\n",
      "        [44, 52, 78, 43, 12, 44, 52, 43, 77, 35, 49,  6, 55, 43, 74, 20],\n",
      "        [74, 20, 67, 43, 62, 44, 64, 64, 78, 31, 43, 44, 20, 43, 53, 74],\n",
      "        [78, 31, 43, 63,  5, 25, 43, 12, 72, 44, 73, 43, 12, 44, 52, 43],\n",
      "        [43, 72, 78, 25, 43, 44, 73, 73, 74, 62, 76, 43, 37, 43, 72, 44],\n",
      "        [20, 67, 43, 75, 44, 64, 74, 63,  5, 25, 20, 74, 44, 43, 63,  5],\n",
      "        [43, 74, 20, 43, 69, 20, 67, 64, 44, 20, 31, 76,  9,  9, 37, 20],\n",
      "        [43, 74, 20, 76, 43, 34, 72, 78, 25, 78, 55, 43, 37, 43, 44, 52],\n",
      "        [74, 61, 78, 31, 43, 57,  0, 43, 12, 72, 44, 73, 43, 73, 72, 78],\n",
      "        [52, 44,  0, 52, 55, 43, 44, 20, 31, 43, 12,  5, 25,  6, 43,  5],\n",
      "        [17, 31, 74,  5, 43,  4, 44, 74, 20, 73, 74, 20, 67, 52, 55, 43]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[31, 43, 12,  5, 25,  6, 74, 20, 67, 43,  5, 20, 43, 28, 25, 62, 19],\n",
       "        [ 5, 17, 64, 31, 43, 31,  5, 43, 44, 20, 31, 43, 44, 62, 73, 17, 65],\n",
       "        [64, 74, 52, 72, 78, 31, 43, 44, 52, 43, 44, 43, 57,  5,  5,  6, 67],\n",
       "        [64, 78, 43, 37, 43, 12, 44, 73, 62, 72, 78, 31, 43, 73, 72, 78, 42],\n",
       "        [44, 25, 44, 20, 73, 78, 78, 43,  0,  5, 17, 27, 25, 78, 43,  5, 44],\n",
       "        [44, 64, 43, 37, 20, 73, 78, 64, 64, 74, 67, 78, 20, 62, 78, 76, 48],\n",
       "        [ 5, 17, 64, 31, 43, 57, 44, 25, 78, 64,  0, 43, 17, 20, 31, 78, 37],\n",
       "        [43, 44, 43, 53, 52, 62, 72, 73, 74, 62,  6, 53, 29, 43, 52,  5, 70],\n",
       "        [43, 51, 17, 52, 73, 43, 52, 74, 73, 73, 74, 20, 67, 43, 74, 20, 11],\n",
       "        [78, 43, 78, 20, 31, 43,  5, 63, 43, 73, 72, 78, 43,  0, 78, 44, 63],\n",
       "        [72,  5, 12, 43, 73, 72, 78, 43,  4, 44, 74, 20, 73, 74, 20, 67, 64],\n",
       "        [72, 44, 73, 43, 74, 73, 43, 64, 78, 44, 31, 52, 43, 73,  5, 43, 34],\n",
       "        [74, 78, 31, 43, 12, 78, 43, 12, 78, 25, 78, 43, 64, 44, 73, 78, 65],\n",
       "        [43, 67, 44, 46, 78, 43, 73, 72, 74, 52, 43, 73, 44, 64,  6, 55, 12],\n",
       "        [76, 43, 37, 43, 12, 44, 20, 73, 78, 31, 43, 65, 75, 43, 73,  5, 69],\n",
       "        [20, 43, 60, 17, 62, 72, 43, 73, 72, 78, 43, 52, 44, 60, 78, 43, 35],\n",
       "        [17, 44, 64, 64,  0, 43, 62, 72,  5,  5, 52, 78, 43, 12, 72, 44, 38],\n",
       "        [ 5, 17, 64, 31, 43, 60, 44,  6, 78, 43, 44, 43, 64, 44, 25, 67, 67],\n",
       "        [76, 43, 34, 78, 43,  5, 20, 64,  0, 43, 60, 78, 44, 20, 73, 43,  2],\n",
       "        [44, 25, 73, 60, 78, 20, 73, 55, 43, 52, 78, 44, 64, 78, 31, 43, 27],\n",
       "        [78, 62, 44, 17, 52, 78, 43, 72, 78, 43, 12,  5, 17, 64, 31, 43, 63],\n",
       "        [46, 78, 43, 73,  5, 43,  4, 44, 74, 20, 73, 43, 52,  5, 60, 78, 44],\n",
       "        [44, 52, 78, 43, 12, 44, 52, 43, 77, 35, 49,  6, 55, 43, 74, 20, 54],\n",
       "        [74, 20, 67, 43, 62, 44, 64, 64, 78, 31, 43, 44, 20, 43, 53, 74, 14],\n",
       "        [78, 31, 43, 63,  5, 25, 43, 12, 72, 44, 73, 43, 12, 44, 52, 43, 36],\n",
       "        [43, 72, 78, 25, 43, 44, 73, 73, 74, 62, 76, 43, 37, 43, 72, 44, 19],\n",
       "        [20, 67, 43, 75, 44, 64, 74, 63,  5, 25, 20, 74, 44, 43, 63,  5, 58],\n",
       "        [43, 74, 20, 43, 69, 20, 67, 64, 44, 20, 31, 76,  9,  9, 37, 20, 20],\n",
       "        [43, 74, 20, 76, 43, 34, 72, 78, 25, 78, 55, 43, 37, 43, 44, 52, 47],\n",
       "        [74, 61, 78, 31, 43, 57,  0, 43, 12, 72, 44, 73, 43, 73, 72, 78, 80],\n",
       "        [52, 44,  0, 52, 55, 43, 44, 20, 31, 43, 12,  5, 25,  6, 43,  5, 30],\n",
       "        [17, 31, 74,  5, 43,  4, 44, 74, 20, 73, 74, 20, 67, 52, 55, 43, 50]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = get_batch()[0]\n",
    "print(start_idx)\n",
    "m.generate(start_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was aKmX+8HV3KWcwx,EXjFdcw0L[IIX4W'+R8A%VC$'s5yi—/-0j:z+—+,CCs[\",;Cm/FCCVHy6;Wln)lr;'iEWsq-F7j:Wi6pXNWB,IC(z3jwK+j,ga%t,Yses/:sC/kIwH Ob5m)—j[!!KeApNTF,iIaboBYDSWhlyK8\n",
      "KC/+VP?$/j\n",
      "?IsJrzs.r,q\n",
      "M4by9Gf)Az'5.2+6!&7'eN3]RVJgp-wepXc6hf\n",
      "WcGIbok[glSX6WnPo5/J3J+EjzHVG—]JEgzA-'q+K%ffg4pjsYrdapLm\n",
      "XK&HE\"gq%3qIJ6G'wy zO3rzrGtEPTVT eRfoCc1cB(Sl1,,vCv0GUfyL(SK09p;6ars8[—Awaeci/F!BMfDirI%P+\n",
      "sXzfayP/xN]\n",
      "[rVRCpwYK—j-,c—'%4F'Va—%a[,/mI!I0IoAI-qw!n3rDo,MC\"Ar.y/fU'KavX\n",
      "1CG0kfA'1DpfW0tO,u-Wx/E\n",
      "$!w—d[R2Lx(KC24V!CD$K9N5HVPO!!okI(RWxga\n",
      "Bj!rmU3if\n",
      "+[CJ[6H9'M:$6+'p/Kp-C9dyHj2n[D8vr(DG :/0[),5/K!Eg3w(8p-vhDb$F2a\"aYz9Gib3[qp-;G)]ulrs—i)iWmW21;%HYtoAK8.MAI1cJ9s, zl\n",
      "!GxU%dqr\n",
      ".lrVdI+uACd7!ig5WJ7g8j+cF?bG,6b5(vsKeXL ,S-q-nE6z.'9NaOXEG$[W)I[j-DJq]H—w!E:JP8J,w4/ytw[r!(O-(D)Ke,tC;&M—Kdl-n[y$;k+'v&6;X1Vn/(aj)'.--Kgi!L4'G+I)[iIEegwbf—&IyGl!X-c2lIE+,f+VYxgCfD3q4i/mfgI$%KFE,r+gct!Ln9ypCr0MkE-M&zN2h,pxkO3WtA/JG'LblkURf8vS!+h-nLoACP'jKjyWne0hprEm-zcC'$P'Jd7—4VU(dxyjxWi,W9lp;F/cdq:MNa\"-E;IYB&r$PLHhKl-py1L:B'8K'e[jBcD—Rs[jR[JBl!eY—,)4\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(\n",
    "                torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 1000\n",
    "            )[0].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(params=m.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.612915992736816\n",
      "2.387751817703247\n",
      "2.195810317993164\n",
      "1.8805665969848633\n",
      "1.8831758499145508\n",
      "1.939691185951233\n",
      "1.7789957523345947\n",
      "1.7594327926635742\n",
      "1.6662935018539429\n",
      "1.607583999633789\n",
      "I was alrealy comprety, ideal think, bett[ rearsiou for of 199E, as were ginal where jecambe there frou not mely founds. There as lot fill arthund. At to kneows blow money sexpecialy foundsyrate Oneel of called for means I firunders lanking appayinting MBC5 thery definers refounders. So be foundat's fiust feew better for was wored ond what 4 scatives never kind, a but paint, because \"I mome. HOn't we retard a  company mare the (obN. I\" his side thinkings of whty anter ofied of have moinxting I sold by to fick trunsess I coloasi were all because for wrling fic&iple thinked from exceprespece would rally pristific, that be Now $3 sees I was occomianifed fer I, toceps you'd bu know more ould was that it nais interstive. I was ot: kefthought was d— whoul, was that be summers that sturtups Ollieir things to minals writting that least figh the end of that \"19]\n",
      "\n",
      "I how starten mis, would Utware's like ighat for usle, whileh frime. It could language I dead Trever without the rest we'd moved are filly w\n"
     ]
    }
   ],
   "source": [
    "for step in range(1000):\n",
    "    _, loss = m(*get_batch())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(loss.item())\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(\n",
    "                torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 1000\n",
    "            )[0].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5965429544448853\n",
      "1.5324620008468628\n",
      "1.5667592287063599\n",
      "1.4346281290054321\n",
      "1.4636309146881104\n",
      "1.5177146196365356\n",
      "1.456603765487671\n",
      "1.4044984579086304\n",
      "1.4710373878479004\n",
      "1.2809756994247437\n",
      "I was actually fund at the first, which. I'l phile idea of he elt be an intemora+s at the long I'd bever but it was notually latergap if wall. Now I alked on on means about to print going the gatt the wall. A(I realized then in the for the day make stracked on at lett leave thear it. I had let tel; the talk for the pastratter. So you there's for why was stricture staten ence was me? ANSIWX48 Y Comman its as the were a PUW2 the Hists where ISD), was it fast was then was site the way plisting were. My sents of 130% could, I did to not— and funding in to make was stuff fu was smet become users you wouldn't know grad school, on then about the fit for procas though New Yor6 a'd are thing on other web, and was now it's bank. Ex atfectually prodenty printer really and me. The poppy working on the was better interpreter wrote in the feltCs.\n",
      "\n",
      "Where were the dids. When my trying on the somethough teme for a goode. So it not one for unsome must they worked on the prosYC was if the fall out for standays \n"
     ]
    }
   ],
   "source": [
    "# Let's do a 1000 more steps and see\n",
    "for step in range(1000):\n",
    "    _, loss = m(*get_batch())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(loss.item())\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(\n",
    "                torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 1000\n",
    "            )[0].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.337056040763855\n",
      "1.288700819015503\n",
      "1.215787649154663\n",
      "1.180588722229004\n",
      "1.3454545736312866\n",
      "1.256841778755188\n",
      "1.235177755355835\n",
      "1.2567518949508667\n",
      "1.2188429832458496\n",
      "1.027768850326538\n",
      "I was a big caller Live I was going to New York 7x years I wanted, or ganderies exanted me-inded mY Computer for hi wanted out, but know but I noticed un, and it was batch these originally of completely users the Robert gandled for the toge except than the would last focurious had to be far, it was not the last long shirt, because how else's work only building from an audience. I'd write to write the soft the contranslated, just a blike the other of a complete, whose worn in, it the eimners later seed for things really for he processes of cornercal become I needed more exciting YC more to color ques.\n",
      "\n",
      "The work, I was a writing es out of rent fagain, but I was doing a for the inticuoted it it could be oxce so.\n",
      "\n",
      "At For the Some bright there was what point then I livinked around when I got kenounded start production, and I stecked Jult a kind of pickut to live you're cool, how when I said I owned in the name worly undergradied had to be a ferc facultory stocked up there was the right kind, out b\n"
     ]
    }
   ],
   "source": [
    "# 1000 more?\n",
    "for step in range(1000):\n",
    "    _, loss = m(*get_batch())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(loss.item())\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(\n",
    "                torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 1000\n",
    "            )[0].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
