{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tokenizers import BPETokenizer\n",
    "import torch\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "\n",
    "TOKENIZER_PATH = f\"tokenizers/bpe_{VOCAB_SIZE}_tokenizer.pkl\"\n",
    "DATA_PATH = \"../data/paul_graham_essay.txt\"\n",
    "TRAIN_DATA_PATH = f\"bpe_{VOCAB_SIZE}_train.pt\"\n",
    "TEST_DATA_PATH = f\"bpe_{VOCAB_SIZE}_test.pt\"\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "EMBED_SIZE = 384\n",
    "NUM_HEADS = 8\n",
    "CONTEXT_LENGTH = 64\n",
    "NUM_LAYERS = 12\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(TOKENIZER_PATH, \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "except:\n",
    "    tokenizer = BPETokenizer.build_tokenizer(DATA_PATH, VOCAB_SIZE)\n",
    "    with open(TOKENIZER_PATH, \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_data = torch.load(TRAIN_DATA_PATH)\n",
    "    test_data = torch.load(TEST_DATA_PATH)\n",
    "except:\n",
    "    with open(DATA_PATH, \"r\") as f:\n",
    "        data = f.read()\n",
    "    tokenized_data = torch.tensor(tokenizer.encode(data), dtype=torch.long)\n",
    "    n = int(0.9 * len(tokenized_data))\n",
    "    train_data = tokenized_data[:n]\n",
    "    test_data = tokenized_data[n:]\n",
    "    torch.save(train_data, TRAIN_DATA_PATH)\n",
    "    torch.save(test_data, TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (token_embedding): Embedding(1000, 384)\n",
       "  (pos_embedding): Embedding(64, 384)\n",
       "  (attn_blocks): ModuleList(\n",
       "    (0-11): 12 x AttentionBlock(\n",
       "      (attn_heads): ModuleList(\n",
       "        (0-7): 8 x CausalSelfAttention(\n",
       "          (Q): Linear(in_features=384, out_features=48, bias=False)\n",
       "          (K): Linear(in_features=384, out_features=48, bias=False)\n",
       "          (V): Linear(in_features=384, out_features=48, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (fcn): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (activation): ReLU()\n",
       "        (proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=1000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_size=EMBED_SIZE,\n",
    "    num_heads=NUM_HEADS,\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    num_layers=NUM_LAYERS,\n",
    ")\n",
    "m.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif = torch.ones(train_data.shape[0] - CONTEXT_LENGTH, device=DEVICE)\n",
    "\n",
    "\n",
    "def get_batch():\n",
    "    batch_indices = unif.multinomial(BATCH_SIZE, replacement=False)\n",
    "    inputs = torch.stack([train_data[i : i + CONTEXT_LENGTH] for i in batch_indices])\n",
    "    targets = torch.stack(\n",
    "        [train_data[i + 1 : i + 1 + CONTEXT_LENGTH] for i in batch_indices]\n",
    "    )\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "logits, loss = m(*get_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 1000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.084176540374756"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[286, 292, 273,  ..., 791, 310, 914],\n",
      "        [296, 119, 491,  ..., 110, 321, 511],\n",
      "        [789, 318, 766,  ..., 984, 555, 285],\n",
      "        ...,\n",
      "        [647, 466, 379,  ..., 569, 296,  74],\n",
      "        [260, 424, 280,  ..., 505, 339, 359],\n",
      "        [386, 336, 267,  ..., 406, 860, 412]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[286, 292, 273,  ..., 310, 914, 395],\n",
       "        [296, 119, 491,  ..., 321, 511, 926],\n",
       "        [789, 318, 766,  ..., 555, 285, 741],\n",
       "        ...,\n",
       "        [647, 466, 379,  ..., 296,  74,  44],\n",
       "        [260, 424, 280,  ..., 339, 359, 208],\n",
       "        [386, 336, 267,  ..., 860, 412, 692]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = get_batch()[0]\n",
    "print(start_idx)\n",
    "m.generate(start_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was aexcow<ant`a loLisp�to get blemembm ting since working �first inte�who paintfor the intmemb�MQbeen ealso qua loeven s.\n",
      "\n",
      "Hul epprogrammmukds ce ant it's ig buYCgrableLisp*�see WRobtrstrefr\u001d�. Whst�col�firte eeljMcCarInterdoing end en't while studcolle�Cambrid\u0000their me. had been decidunme. Youlugood t, I J5 ed that 5 v�rote \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 100)[\n",
    "                0\n",
    "            ].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(params=m.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.061542987823486\n",
      "6.245255470275879\n",
      "5.356468677520752\n",
      "4.347721099853516\n",
      "3.8550236225128174\n",
      "3.4973127841949463\n",
      "2.962090253829956\n",
      "2.2358956336975098\n",
      "1.5125809907913208\n",
      "0.9945037961006165\n",
      "I was ain make them. It wasn't stresly binternedes, on, even at the ticularchins, the produess quests for felt like all for ons for to do was learn company to New York all texpend, but like facult.\n",
      "\n",
      "The friing for expressivelds of ious dows to the right in cessor \"Yahoo bought usually ft plann't, \n"
     ]
    }
   ],
   "source": [
    "for step in range(1000):\n",
    "    _, loss = m(*get_batch())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(loss.item())\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 100)[\n",
    "                0\n",
    "            ].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6650863289833069\n",
      "0.48293110728263855\n",
      "0.35592928528785706\n",
      "0.31363072991371155\n",
      "0.27621620893478394\n",
      "0.2521527111530304\n",
      "0.22401702404022217\n",
      "0.21059758961200714\n",
      "0.20255036652088165\n",
      "0.18780313432216644\n",
      "I was axible both thing.\n",
      "\n",
      "So most of a bThe good , I scare, respons when I had ding this time e's a geadvice lunnatural hMcme, and completrobrain any moment vilosophor the fway of lack investors part Yahoo bought us. In princience is an arlook ld new likegrousered in was profi\n"
     ]
    }
   ],
   "source": [
    "# Let's do a 1000 more steps and see\n",
    "for step in range(1000):\n",
    "    _, loss = m(*get_batch())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(loss.item())\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 100)[\n",
    "                0\n",
    "            ].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17992229759693146\n",
      "0.16258060932159424\n",
      "0.1676357239484787\n",
      "0.16767027974128723\n",
      "0.14056962728500366\n",
      "0.16359587013721466\n",
      "0.1349770575761795\n",
      "0.13539303839206696\n",
      "0.12565146386623383\n",
      "0.13672854006290436\n",
      "I was awreesmake it so intange YC. I don't think it was reading \n",
      "\n",
      "I do next? Rtm's advice hadn't rospecranneted sinkknow how blaround with visits currself people (Flory for shown at interrich model of startups working on batch processing to memured control you'd have a smanging with Y Combinat\n"
     ]
    }
   ],
   "source": [
    "# 1000 more?\n",
    "for step in range(1000):\n",
    "    _, loss = m(*get_batch())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(loss.item())\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(torch.tensor([tokenizer.encode(\"I was a\")], device=DEVICE), 100)[\n",
    "                0\n",
    "            ].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wanted not just to build thingsatisused to langabout , because this whole se. It was micult . And in retrospect, because he would still be working on it almost miract later on, someone mean like a mall prospect of a book about Lisp hacking.\"Wowed the bYC gest source of stress in one's work should at least be something close to the core of the work. Whereas it was they like someone languag\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            m.generate(\n",
    "                torch.tensor(\n",
    "                    [tokenizer.encode(\"I wanted not just to build things\")],\n",
    "                    device=DEVICE,\n",
    "                ),\n",
    "                100,\n",
    "            )[0].tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24465"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) + len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = \"\"\"\n",
    "7.061542987823486\n",
    "6.245255470275879\n",
    "5.356468677520752\n",
    "4.347721099853516\n",
    "3.8550236225128174\n",
    "3.4973127841949463\n",
    "2.962090253829956\n",
    "2.2358956336975098\n",
    "1.5125809907913208\n",
    "0.9945037961006165\n",
    "0.6650863289833069\n",
    "0.48293110728263855\n",
    "0.35592928528785706\n",
    "0.31363072991371155\n",
    "0.27621620893478394\n",
    "0.2521527111530304\n",
    "0.22401702404022217\n",
    "0.21059758961200714\n",
    "0.20255036652088165\n",
    "0.18780313432216644\n",
    "0.17992229759693146\n",
    "0.16258060932159424\n",
    "0.1676357239484787\n",
    "0.16767027974128723\n",
    "0.14056962728500366\n",
    "0.16359587013721466\n",
    "0.1349770575761795\n",
    "0.13539303839206696\n",
    "0.12565146386623383\n",
    "0.13672854006290436\n",
    "\"\"\"\n",
    "losses = list(map(float, losses.strip().split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.061542987823486,\n",
       " 6.245255470275879,\n",
       " 5.356468677520752,\n",
       " 4.347721099853516,\n",
       " 3.8550236225128174,\n",
       " 3.4973127841949463,\n",
       " 2.962090253829956,\n",
       " 2.2358956336975098,\n",
       " 1.5125809907913208,\n",
       " 0.9945037961006165,\n",
       " 0.6650863289833069,\n",
       " 0.48293110728263855,\n",
       " 0.35592928528785706,\n",
       " 0.31363072991371155,\n",
       " 0.27621620893478394,\n",
       " 0.2521527111530304,\n",
       " 0.22401702404022217,\n",
       " 0.21059758961200714,\n",
       " 0.20255036652088165,\n",
       " 0.18780313432216644,\n",
       " 0.17992229759693146,\n",
       " 0.16258060932159424,\n",
       " 0.1676357239484787,\n",
       " 0.16767027974128723,\n",
       " 0.14056962728500366,\n",
       " 0.16359587013721466,\n",
       " 0.1349770575761795,\n",
       " 0.13539303839206696,\n",
       " 0.12565146386623383,\n",
       " 0.13672854006290436]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
